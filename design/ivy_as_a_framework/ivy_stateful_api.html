<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ivy Stateful API &mdash; Ivy 1.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="icon" type="image/png" href="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/ivy_logo_only.png?raw=true">
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Ivy Array" href="ivy_array.html" />
    <link rel="prev" title="Ivy Container" href="ivy_container.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Ivy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../background.html">Background</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../design.html">Design</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../building_blocks.html">Building Blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ivy_as_a_transpiler.html">Ivy as a Transpiler</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../ivy_as_a_framework.html">Ivy as a Framework</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ivy_container.html">Ivy Container</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Ivy Stateful API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#modules">Modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#initializers">Initializers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#optimizers">Optimizers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ivy_array.html">Ivy Array</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../roadmap.html">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_dive.html">Deep Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/activations.html">Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/compilation.html">Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/constants.html">Constants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/creation.html">Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/data_type.html">Data type</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/device.html">Device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/elementwise.html">Elementwise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/general.html">General</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/gradients.html">Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/image.html">Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/linear_algebra.html">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/losses.html">Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/manipulation.html">Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/meta.html">Meta</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/nest.html">Nest</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/norms.html">Norms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/random.html">Random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/searching.html">Searching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/set.html">Set</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/sorting.html">Sorting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/statistical.html">Statistical</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional/ivy/utility.html">Utility</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Stateful</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/activations.html">Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/initializers.html">Initializers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/module.html">Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/norms.html">Norms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/optimizers.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stateful/sequential.html">Sequential</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ivy"">Ivy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mech"">Ivy mech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../vision"">Ivy vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../robot"">Ivy robot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gym"">Ivy gym</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../memory"">Ivy memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../builder"">Ivy builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models"">Ivy models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ecosystem"">Ivy ecosystem</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Ivy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../design.html">Design</a> &raquo;</li>
          <li><a href="../ivy_as_a_framework.html">Ivy as a Framework</a> &raquo;</li>
      <li>Ivy Stateful API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/design/ivy_as_a_framework/ivy_stateful_api.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ivy-stateful-api">
<h1>Ivy Stateful API<a class="headerlink" href="#ivy-stateful-api" title="Permalink to this heading"></a></h1>
<p>Here we explain how Ivy’s stateful API builds on the functional API and the <code class="code docutils literal notranslate"><span class="pre">ivy.Container</span></code> class to provide other convenient classes in the form of optimizers, network layers and custom trainable modules, which help get your ML projects up and running very quickly!</p>
<p>So, without further ado, let’s walk through what the stateful API has to offer!</p>
<section id="modules">
<h2>Modules<a class="headerlink" href="#modules" title="Permalink to this heading"></a></h2>
<p>The most helpful stateful Ivy class is perhaps the <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code>. This can be used to create custom trainable layers or entire networks. Manually defined trainable variables must be specified in the <code class="code docutils literal notranslate"><span class="pre">_create_variables</span></code> method. For example, we can create a linear layer by deriving from <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                 <span class="n">with_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dev</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span> <span class="o">=</span> <span class="n">input_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_w_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_channels</span><span class="p">,)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_with_bias</span> <span class="o">=</span> <span class="n">with_bias</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dev</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;w&#39;</span><span class="p">:</span> <span class="n">ivy</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_w_shape</span><span class="p">,</span> <span class="n">dev</span><span class="o">=</span><span class="n">dev</span><span class="p">)}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_with_bias</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="o">**</span><span class="n">v</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">ivy</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span>
                        <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_b_shape</span><span class="p">,</span> <span class="n">dev</span><span class="o">=</span><span class="n">dev</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">w</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">b</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_with_bias</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>For simplicity, this is slightly different to the builtin <code class="code docutils literal notranslate"><span class="pre">ivy.Linear</span></code> in a couple of ways, as we will explain in the Initializer section below.</p>
<p>All <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instances have an attribute v (short for variables), which stores all of the trainable variables in the module in an <code class="code docutils literal notranslate"><span class="pre">ivy.Container</span></code>. For our example above, the hierarchical structure of these variables is the same as that defined in the method <code class="code docutils literal notranslate"><span class="pre">_create_variables</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">linear</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.8979</span><span class="p">,</span> <span class="mf">0.3198</span><span class="p">,</span> <span class="mf">0.0196</span><span class="p">,</span> <span class="mf">0.3126</span><span class="p">]),</span>
    <span class="n">w</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3717</span><span class="p">,</span> <span class="mf">0.9687</span><span class="p">],</span>
               <span class="p">[</span><span class="mf">0.6958</span><span class="p">,</span> <span class="mf">0.5122</span><span class="p">],</span>
               <span class="p">[</span><span class="mf">0.3902</span><span class="p">,</span> <span class="mf">0.8800</span><span class="p">],</span>
               <span class="p">[</span><span class="mf">0.5613</span><span class="p">,</span> <span class="mf">0.1982</span><span class="p">]])</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This is all well and good for defining a single layer, but manually defining all variables in <code class="code docutils literal notranslate"><span class="pre">_create_variables</span></code> for very complex networks would be a total nightmare.</p>
<p>To overcome this issue, modules can be nested up to an arbitrary depth. This means we can very easily create more complex networks as compositions of other sub-modules or layers. For example, we can create a simple fully connected network with our linear layers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FC</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear0</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear0</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>In this case, we don’t specify any variables manually using <code class="code docutils literal notranslate"><span class="pre">_create_variables</span></code>. This is because all variables in the network reside in the linear layers. These variables are all detected automatically.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fc</span> <span class="o">=</span> <span class="n">FC</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fc</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">linear0</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
        <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="p">},</span>
    <span class="n">linear1</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.9563</span><span class="p">]),</span>
        <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Not only are variables detected automatically for <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instances which are direct attributes of the top-level class, as above, but also if they are contained within any nested structure which is itself an attribute of the top-level class, such as lists, tuples or dicts. These all work up to an arbitrary nested depth. Check out some of the different ways of defining network layers and how this impacts the variable structure below.</p>
<p>As a list:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FC</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="p">[</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>

<span class="n">fc</span> <span class="o">=</span> <span class="n">FC</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fc</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">linear</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">v0</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="p">},</span>
        <span class="n">v1</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.6440</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>As a tuple:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FC</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>

<span class="n">fc</span> <span class="o">=</span> <span class="n">FC</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fc</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">linear</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">v0</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="p">},</span>
        <span class="n">v1</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.6440</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>As a dict:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FC</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;key0&#39;</span><span class="p">:</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
                       <span class="s1">&#39;key1&#39;</span><span class="p">:</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)}</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="s1">&#39;key0&#39;</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="s1">&#39;key1&#39;</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>

<span class="n">fc</span> <span class="o">=</span> <span class="n">FC</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fc</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">linear</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">key0</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="p">},</span>
        <span class="n">key1</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.1823</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>As a nested list:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FC</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="p">[[</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)],</span>
                       <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">linear</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>

<span class="n">fc</span> <span class="o">=</span> <span class="n">FC</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fc</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">linear</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">v0</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">v0</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
                <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
            <span class="p">},</span>
            <span class="n">v1</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
                <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="n">v1</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.8075</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Duplicates are also handled correctly, if for example a layer is stored both as a direct attribute and also within a list:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FC</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear0</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear3</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">linear0</span><span class="p">,</span>
                       <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">,</span>
                       <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)]</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">[</span><span class="mi">3</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>

<span class="n">fc</span> <span class="o">=</span> <span class="n">FC</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fc</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">linear</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">v0</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="p">},</span>
        <span class="n">v1</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
        <span class="p">},</span>
        <span class="n">v2</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="n">linear3</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.2346</span><span class="p">]),</span>
        <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>While the examples above all use the functional API for calling the ReLU and Sigmoid activation functions, we can also call these using the stateful API like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FC</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear0</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear0</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>It may seem counter intuitive to implement the activation as an <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code>, as there are no hidden trainable weights. However, for networks where modules are directly chained together, and all outputs from the preceding module are fed as inputs to the subsequent module, then we can use the <code class="code docutils literal notranslate"><span class="pre">ivy.Sequential</span></code> class. This can simplify the construction of our small fully connected network even further.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fc</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">fc</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="p">{</span>
    <span class="n">submodules</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">v0</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="p">},</span>
        <span class="n">v1</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">b</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.1300</span><span class="p">]),</span>
            <span class="n">w</span><span class="p">:</span> <span class="p">(</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Given that the weights of our network are stored in an <code class="code docutils literal notranslate"><span class="pre">ivy.Container</span></code>, and the gradients returned from <code class="code docutils literal notranslate"><span class="pre">ivy.execute_with_gradients</span></code> are also stored in an <code class="code docutils literal notranslate"><span class="pre">ivy.Container</span></code>, all operations are applied recursively to every variable at all leaves. Therefore, we can train the network in a few lines of code like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_in</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">out</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">execute_with_gradients</span><span class="p">(</span>
        <span class="n">loss_fn</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">v</span> <span class="o">-</span> <span class="n">grads</span> <span class="o">*</span> <span class="n">lr</span>
</pre></div>
</div>
</section>
<section id="initializers">
<h2>Initializers<a class="headerlink" href="#initializers" title="Permalink to this heading"></a></h2>
<p>In the examples above, we defined how the trainable weights should be initialized directly in the <code class="code docutils literal notranslate"><span class="pre">_create_variables</span></code> method. However, it would be better if we could decouple the initialization scheme from the layer implementation. This is where the <code class="code docutils literal notranslate"><span class="pre">ivy.Initializer</span></code> class comes in. The actual implementation for the <code class="code docutils literal notranslate"><span class="pre">ivy.Linear</span></code> layer exposed in the Ivy stateful API is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/stateful/layers.py</span>
<span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span>
                 <span class="n">weight_initializer</span><span class="o">=</span><span class="n">GlorotUniform</span><span class="p">(),</span>
                 <span class="n">bias_initializer</span><span class="o">=</span><span class="n">Zeros</span><span class="p">(),</span> <span class="n">with_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">dev</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span> <span class="o">=</span> <span class="n">input_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_w_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_channels</span><span class="p">,)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_w_init</span> <span class="o">=</span> <span class="n">weight_initializer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b_init</span> <span class="o">=</span> <span class="n">bias_initializer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_with_bias</span> <span class="o">=</span> <span class="n">with_bias</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dev</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;w&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_w_init</span><span class="o">.</span><span class="n">create_variables</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_w_shape</span><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_input_channels</span><span class="p">)}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_with_bias</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="o">**</span><span class="n">v</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_b_init</span><span class="o">.</span><span class="n">create_variables</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">_b_shape</span><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_channels</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">w</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">b</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_with_bias</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="code docutils literal notranslate"><span class="pre">ivy.Initializer</span></code> class has a single abstract method, <code class="code docutils literal notranslate"><span class="pre">create_variables(var_shape,</span> <span class="pre">dev,</span> <span class="pre">fan_out=None,</span> <span class="pre">fan_in=None,</span> <span class="pre">*args,</span> <span class="pre">**kwargs)</span></code>. Check out the <a class="reference external" href="https://github.com/unifyai/ivy/blob/master/ivy/stateful/initializers.py">code</a> or <a class="reference external" href="https://lets-unify.ai/ivy/neural_net_stateful/initializers.html">docs</a> for more details. The default initializer for the weights is <code class="code docutils literal notranslate"><span class="pre">ivy.GlorotUniform</span></code> and for this bias is <code class="code docutils literal notranslate"><span class="pre">ivy.Zeros</span></code>. Let’s take a quick look at what these look like. <code class="code docutils literal notranslate"><span class="pre">ivy.GlorotUniform</span></code> derives from a more general <code class="code docutils literal notranslate"><span class="pre">ivy.Uniform</span></code> initializer class, and is then simply implemented as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/stateful/initializers.py</span>
<span class="k">class</span> <span class="nc">GlorotUniform</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Uniform</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">numerator</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">fan_mode</span><span class="o">=</span><span class="s1">&#39;fan_sum&#39;</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="code docutils literal notranslate"><span class="pre">ivy.Zeros</span></code> derives from a more general <code class="code docutils literal notranslate"><span class="pre">ivy.Constant</span></code> initializer class, and is then simply implemented as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/stateful/initializers.py</span>
<span class="k">class</span> <span class="nc">Zeros</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Constant</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">constant</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
</pre></div>
</div>
<p>The initializers are not stateful, and so adding them to the “stateful API” is a slight misnomer. However, the dedicated initializer class helps us to decouple initialization schemes from layer implementations, which are themselves stateful. Given that their application is entirely specific to stateful <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instances, they still belong in the stateful API.</p>
</section>
<section id="optimizers">
<h2>Optimizers<a class="headerlink" href="#optimizers" title="Permalink to this heading"></a></h2>
<p>Recapping the example given above, we saw that <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instances can be trained like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_in</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">out</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">execute_with_gradients</span><span class="p">(</span>
        <span class="n">loss_fn</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">v</span> <span class="o">-</span> <span class="n">grads</span> <span class="o">*</span> <span class="n">lr</span>
</pre></div>
</div>
<p>However, what if we want to do something more complex than vanilla gradient descent? What about ADAM or other stateful optimizers such as LARS and LAMB? This is where the <code class="code docutils literal notranslate"><span class="pre">ivy.Optimizer</span></code> class comes in.</p>
<p>Let’s take the class <code class="code docutils literal notranslate"><span class="pre">ivy.Adam</span></code> as an example. The implementation is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/stateful/optimizers.py</span>
<span class="k">class</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
                 <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">stop_gradients</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compile_on_next_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">dev</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">Optimizer</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">inplace</span><span class="p">,</span> <span class="n">stop_gradients</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">compile_on_next_step</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mw</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vw</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_first_pass</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_should_compile</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Custom Step</span>

    <span class="k">def</span> <span class="nf">_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_first_pass</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mw</span> <span class="o">=</span> <span class="n">grads</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_vw</span> <span class="o">=</span> <span class="n">grads</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_first_pass</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">new_v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mw</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vw</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">adam_update</span><span class="p">(</span>
            <span class="n">v</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lr</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lr</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lr</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mw</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vw</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_count</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_beta1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inplace</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stop_gradients</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_v</span>

    <span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mw</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">mw</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vw</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">vw</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">Container</span><span class="p">({</span><span class="s1">&#39;mw&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mw</span><span class="p">,</span> <span class="s1">&#39;vw&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vw</span><span class="p">})</span>
</pre></div>
</div>
<p>By changing only a couple of lines, we can use this optimizer to train our network like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_in</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">out</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">execute_with_gradients</span><span class="p">(</span>
        <span class="n">loss_fn</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">v</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Round Up</strong></p>
<p>That should hopefully be enough to get you started with Ivy’s stateful API 😊</p>
<p>Please check out the discussions on the <a class="reference external" href="https://github.com/unifyai/ivy">repo</a> for FAQs, and reach out on <a class="reference external" href="https://discord.gg/ZVQdvbzNQJ">discord</a> if you have any questions!</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ivy_container.html" class="btn btn-neutral float-left" title="Ivy Container" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ivy_array.html" class="btn btn-neutral float-right" title="Ivy Array" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2022, Ivy Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>